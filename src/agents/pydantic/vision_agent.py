"""
Vision Agent - Photo analysis specialist.
==========================================
Handles photo identification and product matching.
"""

from __future__ import annotations

import logging
from typing import Any

from openai import AsyncOpenAI
from pydantic_ai import Agent, ImageUrl, RunContext
from pydantic_ai.models.openai import OpenAIChatModel
from pydantic_ai.providers.openai import OpenAIProvider

from src.conf.config import settings
from src.core.prompt_registry import registry

from .deps import AgentDeps
from .models import VisionResponse


logger = logging.getLogger(__name__)

# Vision guide logic replaced by prompt registry


# =============================================================================
# MODEL SETUP
# =============================================================================


def _build_model() -> OpenAIChatModel:
    """Build OpenAI-compatible model for VISION (multimodal).
    
    IMPORTANT: Uses LLM_MODEL_VISION which MUST be a vision-capable model!
    - OpenAI: gpt-5.1, gpt-4o, gpt-4-vision-preview
    - OpenRouter: x-ai/grok-2-vision-1212, openai/gpt-4o
    """
    model_name = settings.LLM_MODEL_VISION  # MUST be vision-capable!
    
    # Detect if model is OpenAI native (gpt-*) or OpenRouter (provider/model)
    is_openai_model = model_name.startswith("gpt-") or model_name.startswith("o1") or model_name.startswith("o3")
    
    if is_openai_model:
        # Use OpenAI directly
        api_key = settings.OPENAI_API_KEY.get_secret_value()
        base_url = "https://api.openai.com/v1"
        if not api_key:
            # Fallback to OpenRouter for OpenAI models
            api_key = settings.OPENROUTER_API_KEY.get_secret_value()
            base_url = settings.OPENROUTER_BASE_URL
            model_name = f"openai/{model_name}"  # OpenRouter format
            logger.info("Vision using OpenRouter for %s (OPENAI_API_KEY missing)", model_name)
    else:
        # Use OpenRouter for other models (x-ai/*, anthropic/*, etc.)
        api_key = settings.OPENROUTER_API_KEY.get_secret_value()
        base_url = settings.OPENROUTER_BASE_URL

    if not api_key:
        logger.error("‚ùå No API key for vision model! Set OPENAI_API_KEY or OPENROUTER_API_KEY.")
        raise ValueError(
            "Vision model requires API key. Set OPENAI_API_KEY or OPENROUTER_API_KEY."
        )

    logger.info("üëÅÔ∏è Vision model: %s (via %s)", model_name, base_url[:30])

    client = AsyncOpenAI(base_url=base_url, api_key=api_key)
    provider = OpenAIProvider(openai_client=client)
    return OpenAIChatModel(model_name, provider=provider)


# =============================================================================
# VISION AGENT PROMPT
# =============================================================================


async def _search_products(
    ctx: RunContext[AgentDeps],
    query: str,
    category: str | None = None,
) -> str:
    """
    –ó–Ω–∞–π—Ç–∏ —Ç–æ–≤–∞—Ä–∏ –≤ –∫–∞—Ç–∞–ª–æ–∑—ñ.

    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π —Ü–µ —â–æ–± –∑–Ω–∞–π—Ç–∏ —Ç–æ–≤–∞—Ä —è–∫–∏–π —Ç–∏ –±–∞—á–∏—à –Ω–∞ —Ñ–æ—Ç–æ.
    –ù–∞–ø—Ä–∏–∫–ª–∞–¥: search_products("—Ä–æ–∂–µ–≤–∞ —Å—É–∫–Ω—è") –∞–±–æ search_products("–∫–æ—Å—Ç—é–º –∑ –ª–∞–º–ø–∞—Å–∞–º–∏")
    """
    products = await ctx.deps.catalog.search_products(query, category)

    if not products:
        return "–ù–∞ –∂–∞–ª—å, –∑–∞ –≤–∞—à–∏–º –∑–∞–ø–∏—Ç–æ–º –Ω—ñ—á–æ–≥–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ."

    lines = ["–ó–Ω–∞–π–¥–µ–Ω—ñ —Ç–æ–≤–∞—Ä–∏:"]
    for p in products:
        name = p.get("name")
        price = p.get("price")
        sizes = ", ".join(p.get("sizes", []))
        colors = ", ".join(p.get("colors", []))
        sku = p.get("sku", "N/A")
        lines.append(f"- {name} (SKU: {sku}, {price} –≥—Ä–Ω). –†–æ–∑–º—ñ—Ä–∏: {sizes}. –ö–æ–ª—å–æ—Ä–∏: {colors}")

    return "\n".join(lines)


async def _load_vision_guide_from_db() -> str:
    """
    Load product visual features from Supabase.

    This replaces the static vision_guide.json with real-time DB data.
    Falls back to JSON if DB is unavailable.
    """
    from src.services.catalog_service import CatalogService

    try:
        catalog = CatalogService()
        products = await catalog.get_products_for_vision()

        if not products:
            logger.warning("üì¶ No products from DB, falling back to JSON")
            return _load_vision_guide_from_json()

        # Log loaded products for debugging
        product_names = [p.get("name", "?") for p in products[:10]]
        logger.info("üì¶ Loaded %d products from DB: %s...", len(products), product_names)

        lines = ["# VISION GUIDE ‚Äî –¢–æ–≤–∞—Ä–∏ –∑ –∫–∞—Ç–∞–ª–æ–≥—É (LIVE DATA)\n"]

        # Group by base model name (strip color)
        for product in products:
            name = product.get("name", "Unknown")
            sku = product.get("sku") or product.get("id", "N/A")
            # Use 'colors' column (plural) as per actual DB schema
            color = product.get("colors") or product.get("color", "")

            lines.append(f"## {name}")
            lines.append(f"- **SKU**: {sku}")
            if color:
                lines.append(f"- **–ö–æ–ª—ñ—Ä**: {color}")

            # Visual features from DB columns
            fabric = product.get("fabric_type")
            if fabric:
                lines.append(f"- **–¢–∫–∞–Ω–∏–Ω–∞**: {fabric}")

            closure = product.get("closure_type")
            if closure:
                closure_map = {
                    "half_zip": "half-zip (–∫–æ—Ä–æ—Ç–∫–∞ –±–ª–∏—Å–∫–∞–≤–∫–∞)",
                    "full_zip": "–ø–æ–≤–Ω–∞ –±–ª–∏—Å–∫–∞–≤–∫–∞",
                    "no_zip": "–±–µ–∑ –±–ª–∏—Å–∫–∞–≤–∫–∏",
                    "buttons": "–≥—É–¥–∑–∏–∫–∏",
                }
                lines.append(f"- **–ó–∞—Å—Ç—ñ–±–∫–∞**: {closure_map.get(closure, closure)}")

            if product.get("has_hood"):
                lines.append("- **–ö–∞–ø—é—à–æ–Ω**: –¢–ê–ö")
            elif product.get("has_hood") is False:
                lines.append("- **–ö–∞–ø—é—à–æ–Ω**: –ù–Ü")

            pants = product.get("pants_style")
            if pants:
                pants_map = {
                    "joggers": "–¥–∂–æ–≥–µ—Ä–∏ (–∑–≤—É–∂–µ–Ω—ñ)",
                    "palazzo": "palazzo (—à–∏—Ä–æ–∫—ñ)",
                    "classic": "–∫–ª–∞—Å–∏—á–Ω—ñ",
                }
                lines.append(f"- **–®—Ç–∞–Ω–∏**: {pants_map.get(pants, pants)}")

            back_view = product.get("back_view_description")
            if back_view:
                lines.append(f"- **–í–∏–¥ –∑–∑–∞–¥—É**: {back_view}")

            # Recognition tips
            tips = product.get("recognition_tips", [])
            if tips:
                lines.append("- **–Ø–∫ —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏**:")
                for tip in tips[:3]:
                    lines.append(f"  - {tip}")

            # Confusion prevention
            confused = product.get("confused_with", [])
            if confused:
                lines.append(f"- **–ù–µ –ø–ª—É—Ç–∞–π –∑**: {', '.join(confused)}")

            # Price (always useful)
            price = product.get("price")
            if price:
                lines.append(f"- **–¶—ñ–Ω–∞**: {price} –≥—Ä–Ω")

            lines.append("")

        # Add detection rules summary
        lines.append(_build_detection_rules_from_products(products))

        return "\n".join(lines)

    except Exception as e:
        logger.warning("Failed to load from DB: %s, falling back to JSON", e)
        return _load_vision_guide_from_json()


def _build_detection_rules_from_products(products: list[dict]) -> str:
    """Build detection rules summary from products."""
    by_fabric: dict[str, list[str]] = {}
    by_closure: dict[str, list[str]] = {}
    by_hood: dict[str, list[str]] = {"–∑ –∫–∞–ø—é—à–æ–Ω–æ–º": [], "–±–µ–∑ –∫–∞–ø—é—à–æ–Ω–∞": []}

    for p in products:
        name = p.get("name", "Unknown")
        # Extract base name (remove color)
        base_name = name.split("(")[0].strip() if "(" in name else name

        fabric = p.get("fabric_type")
        if fabric:
            by_fabric.setdefault(fabric, []).append(base_name)

        closure = p.get("closure_type")
        if closure:
            by_closure.setdefault(closure, []).append(base_name)

        if p.get("has_hood"):
            by_hood["–∑ –∫–∞–ø—é—à–æ–Ω–æ–º"].append(base_name)
        elif p.get("has_hood") is False:
            by_hood["–±–µ–∑ –∫–∞–ø—é—à–æ–Ω–∞"].append(base_name)

    lines = ["\n# DETECTION RULES (–∑ –ë–î)"]

    if by_fabric:
        lines.append("## –ü–æ —Ç–∫–∞–Ω–∏–Ω—ñ:")
        for fabric, names in by_fabric.items():
            unique = list(set(names))[:5]
            lines.append(f"- {fabric}: {', '.join(unique)}")

    if by_closure:
        lines.append("## –ü–æ –∑–∞—Å—Ç—ñ–±—Ü—ñ:")
        for closure, names in by_closure.items():
            unique = list(set(names))[:5]
            lines.append(f"- {closure}: {', '.join(unique)}")

    if by_hood["–∑ –∫–∞–ø—é—à–æ–Ω–æ–º"] or by_hood["–±–µ–∑ –∫–∞–ø—é—à–æ–Ω–∞"]:
        lines.append("## –ü–æ –∫–∞–ø—é—à–æ–Ω—É:")
        if by_hood["–∑ –∫–∞–ø—é—à–æ–Ω–æ–º"]:
            unique = list(set(by_hood["–∑ –∫–∞–ø—é—à–æ–Ω–æ–º"]))[:5]
            lines.append(f"- –ó –∫–∞–ø—é—à–æ–Ω–æ–º: {', '.join(unique)}")
        if by_hood["–±–µ–∑ –∫–∞–ø—é—à–æ–Ω–∞"]:
            unique = list(set(by_hood["–±–µ–∑ –∫–∞–ø—é—à–æ–Ω–∞"]))[:5]
            lines.append(f"- –ë–µ–∑ –∫–∞–ø—é—à–æ–Ω–∞: {', '.join(unique)}")

    return "\n".join(lines)


def _load_model_rules_yaml() -> str:
    """Load model rules from generated YAML file."""
    from pathlib import Path

    import yaml

    rules_path = Path(__file__).parent.parent.parent.parent / "data" / "vision" / "generated" / "model_rules.yaml"

    try:
        with open(rules_path, encoding="utf-8") as f:
            rules = yaml.safe_load(f)

        if not rules:
            return ""

        lines = []

        # Add MODEL_RULES section
        model_rules = rules.get("MODEL_RULES", {})
        for name, data in model_rules.items():
            lines.append(f"## {name}")
            lines.append(f"- **–ö–∞—Ç–µ–≥–æ—Ä—ñ—è**: {data.get('category', '?')}")
            lines.append(f"- **–¢–∫–∞–Ω–∏–Ω–∞**: {data.get('fabric_type', '?')}")
            lines.append(f"- **–¶—ñ–Ω–∞**: {data.get('price', '?')} –≥—Ä–Ω")

            markers = data.get("visual_markers", [])
            if markers:
                lines.append("- **–í—ñ–∑—É–∞–ª—å–Ω—ñ –æ–∑–Ω–∞–∫–∏**:")
                for m in markers:
                    lines.append(f"  - {m}")

            identify = data.get("identify_by")
            if identify:
                lines.append(f"- **–ì–û–õ–û–í–ù–ê –û–ó–ù–ê–ö–ê**: {identify}")

            confused = data.get("confused_with", [])
            if confused:
                lines.append(f"- **–ù–µ –ø–ª—É—Ç–∞–π –∑**: {', '.join(confused)}")
                if data.get("how_to_distinguish"):
                    lines.append(f"- **–Ø–∫ –≤—ñ–¥—Ä—ñ–∑–Ω–∏—Ç–∏**: {data['how_to_distinguish'].strip()}")
                if data.get("critical_check"):
                    lines.append(f"- **‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–ê –ü–ï–†–ï–í–Ü–†–ö–ê**: {data['critical_check'].strip()}")

            colors = data.get("colors", [])
            if colors:
                lines.append(f"- **–ö–æ–ª—å–æ—Ä–∏**: {', '.join(colors)}")

            lines.append("")

        # Add DECISION_TREE
        decision_tree = rules.get("DECISION_TREE", "")
        if decision_tree:
            lines.append("# DECISION TREE")
            lines.append(decision_tree)

        return "\n".join(lines)

    except Exception as e:
        logger.warning("Failed to load model_rules.yaml: %s", e)
        return ""


def _load_vision_guide_from_json() -> str:
    """Fallback: Load from static JSON file."""
    import json
    from pathlib import Path

    guide_path = Path(__file__).parent.parent.parent.parent / "data" / "vision" / "generated" / "vision_guide.json"

    try:
        with open(guide_path, encoding="utf-8") as f:
            guide = json.load(f)

        products = guide.get("visual_recognition_guide", {}).get("products", {})

        lines = ["# VISION GUIDE (fallback JSON)\n"]

        for sku, data in products.items():
            name = data.get("name", "Unknown")
            tips = data.get("recognition_tips", [])

            lines.append(f"## {name} (SKU: {sku})")
            for tip in tips[:3]:
                lines.append(f"  - {tip}")
            lines.append("")

        return "\n".join(lines)

    except Exception as e:
        logger.warning("Failed to load vision_guide.json: %s", e)
        return ""


def _get_base_vision_prompt() -> str:
    """
    Get base vision prompt (algorithm + rules).

    This is the STATIC part loaded at agent init.
    Product data is loaded DYNAMICALLY via @agent.system_prompt.
    """
    parts = []

    # 1. Load main vision prompt (algorithm)
    try:
        vision_main = registry.get("vision.main").content
        parts.append(vision_main)
    except Exception as e:
        logger.error("Failed to load vision.main: %s", e)
        parts.append("# Vision Agent\n–ê–Ω–∞–ª—ñ–∑—É–π —Ñ–æ—Ç–æ —Ç–∞ –∑–Ω–∞—Ö–æ–¥—å —Ç–æ–≤–∞—Ä–∏ MIRT.")

    # 2. Load model rules from generated file (auto-updated from products_master.yaml)
    try:
        model_rules = _load_model_rules_yaml()
        if model_rules:
            parts.append("\n---\n# MODEL DATABASE\n")
            parts.append(model_rules)
    except Exception as e:
        logger.warning("Model rules not loaded: %s", e)

    # 3. Add confusion prevention table with CRITICAL rules
    parts.append("""
---
# ‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–ï –ü–†–ê–í–ò–õ–û: –õ–ê–ì–£–ù–ê vs –ú–†–Ü–Ø

–¶—ñ –¥–≤–∞ –∫–æ—Å—Ç—é–º–∏ –î–£–ñ–ï —Å—Ö–æ–∂—ñ (–æ–±–∏–¥–≤–∞ –ø–ª—é—à–µ–≤—ñ, –æ–¥–Ω–∞–∫–æ–≤—ñ –∫–æ–ª—å–æ—Ä–∏), –∞–ª–µ –≤—ñ–¥—Ä—ñ–∑–Ω—è—é—Ç—å—Å—è –ó–ê–°–¢–Ü–ë–ö–û–Æ:

| –ú–æ–¥–µ–ª—å | –ó–∞—Å—Ç—ñ–±–∫–∞ | –Ø–∫ –≤–∏–≥–ª—è–¥–∞—î |
|--------|----------|-------------|
| **–õ–ê–ì–£–ù–ê** | –ü–û–í–ù–ê –±–ª–∏—Å–∫–∞–≤–∫–∞ (–≤—ñ–¥ –≥–æ—Ä–ª–∞ –¥–æ –Ω–∏–∑—É) | –ë–ª–∏—Å–∫–∞–≤–∫–∞ –π–¥–µ —á–µ—Ä–µ–∑ –í–ï–°–¨ –ø–µ—Ä–µ–¥ –∫—É—Ä—Ç–∫–∏ |
| **–ú–†–Ü–Ø** | HALF-ZIP (—Ç—ñ–ª—å–∫–∏ –¥–æ –≥—Ä—É–¥–µ–π) | –ë–ª–∏—Å–∫–∞–≤–∫–∞ –∫–æ—Ä–æ—Ç–∫–∞, –∑–≤–µ—Ä—Ö—É 15-20 —Å–º |

üîç –ê–õ–ì–û–†–ò–¢–ú –í–ò–ó–ù–ê–ß–ï–ù–ù–Ø:
1. –ü–æ–¥–∏–≤–∏—Å—å –Ω–∞ –±–ª–∏—Å–∫–∞–≤–∫—É
2. –Ø–∫—â–æ –±–ª–∏—Å–∫–∞–≤–∫–∞ –π–¥–µ –î–û –ù–ò–ó–£ –∫—É—Ä—Ç–∫–∏ = –õ–ê–ì–£–ù–ê
3. –Ø–∫—â–æ –±–ª–∏—Å–∫–∞–≤–∫–∞ –∫–æ—Ä–æ—Ç–∫–∞ (—Ç—ñ–ª—å–∫–∏ –∑–≤–µ—Ä—Ö—É) = –ú–†–Ü–Ø
4. –Ø–∫—â–æ –Ω–µ –≤–∏–¥–Ω–æ –±–ª–∏—Å–∫–∞–≤–∫—É ‚Äî –∑–∞–ø–∏—Ç–∞–π –∫–ª—ñ—î–Ω—Ç–∞!

---
# QUICK CONFUSION PREVENTION

| –Ø–∫—â–æ –±–∞—á–∏—à... | –¶–µ –ù–ï... | –¶–µ... | –ß–æ–º—É? |
|---------------|----------|-------|-------|
| –ü–û–í–ù–£ –±–ª–∏—Å–∫–∞–≤–∫—É –¥–æ –Ω–∏–∑—É | –ú—Ä—ñ—è | **–õ–ê–ì–£–ù–ê** | –ú—Ä—ñ—è = half-zip |
| –ö–æ—Ä–æ—Ç–∫—É –±–ª–∏—Å–∫–∞–≤–∫—É (half-zip) | –õ–∞–≥—É–Ω–∞ | **–ú–†–Ü–Ø** | –õ–∞–≥—É–Ω–∞ = –ø–æ–≤–Ω–∞ |
| –ö–∞–ø—é—à–æ–Ω + –±–∞–≤–æ–≤–Ω–∞ | –ö–∞–ø—Ä–∏–∑ | **–†–ò–¢–ú** | –ö–∞–ø—Ä–∏–∑ = –±–µ–∑ –∫–∞–ø—é—à–æ–Ω–∞ |
| Palazzo + –±–µ–∑ –∫–∞–ø—é—à–æ–Ω–∞ | –†–∏—Ç–º | **–ö–ê–ü–†–ò–ó** | –†–∏—Ç–º = –∑ –∫–∞–ø—é—à–æ–Ω–æ–º |
| –õ–∞–º–ø–∞—Å–∏ –Ω–∞ —à—Ç–∞–Ω–∞—Ö | –†–∏—Ç–º/–ö–∞–ø—Ä–∏–∑ | **–ú–ï–†–ï–Ø** | –¢—ñ–ª—å–∫–∏ –ú–µ—Ä–µ—è –∑ –ª–∞–º–ø–∞—Å–∞–º–∏ |
| –°–º—É–∂–∫–∞ –Ω–∞ –±–ª—É–∑—ñ | –ö–∞–ø—Ä–∏–∑ | **–í–ê–õ–ï–†–Ü** | –í–∞–ª–µ—Ä—ñ = —Å–º—É–∂–∫–∞ |
| –ë–ª–∏—Å–∫—É—á–∞ —Ç–∫–∞–Ω–∏–Ω–∞ + –ø–æ—è—Å | –ö–æ—Å—Ç—é–º | **–¢–†–ï–ù–ß** | –ï–∫–æ—à–∫—ñ—Ä–∞ –±–ª–∏—â–∏—Ç—å |

–í–ê–ñ–õ–ò–í–û:
- –Ø–∫—â–æ —Ñ–æ—Ç–æ –∑—ñ —Å–ø–∏–Ω–∏ ‚Äî —à—É–∫–∞–π back_view –æ–∑–Ω–∞–∫–∏!
- –Ø–∫—â–æ —Å–∫—Ä—ñ–Ω—à–æ—Ç ‚Äî —à—É–∫–∞–π —Ç–µ–∫—Å—Ç—É—Ä—É —Ç–∞ —Å–∏–ª—É–µ—Ç!
- –ó–ê–í–ñ–î–ò –≤–∏–∫–ª–∏—á search_products() –¥–ª—è –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–Ω—è!
- –ó–ê–í–ñ–î–ò –í–ò–ó–ù–ê–ß–ê–ô –¢–û–í–ê–†! –ù–ï –°–£–ú–ù–Ü–í–ê–ô–°–Ø! –°–ª—ñ–¥—É–π vision_guide!

---
# üé® –ö–†–ò–¢–ò–ß–ù–û: –†–û–ó–†–Ü–ó–ù–Ø–ô –ö–û–õ–¨–û–†–ò!

**–ü–û–ú–ê–†–ê–ù–ß–ï–í–ò–ô ‚â† –ñ–û–í–¢–ò–ô!** –¶–µ –†–Ü–ó–ù–Ü –∫–æ–ª—å–æ—Ä–∏!

| –ö–æ–ª—ñ—Ä | –Ø–∫ –≤–∏–≥–ª—è–¥–∞—î | –ù–ï –ü–õ–£–¢–ê–ô –∑ |
|-------|-------------|-------------|
| **–ü–û–ú–ê–†–ê–ù–ß–ï–í–ò–ô** | –Ø—Å–∫—Ä–∞–≤–∏–π, —Ç–µ–ø–ª–∏–π, —è–∫ –∞–ø–µ–ª—å—Å–∏–Ω üçä | –∂–æ–≤—Ç–∏–π |
| **–ñ–û–í–¢–ò–ô** | –°–≤—ñ—Ç–ª–∏–π, –ª–∏–º–æ–Ω–Ω–∏–π, —Ö–æ–ª–æ–¥–Ω–∏–π üçã | –ø–æ–º–∞—Ä–∞–Ω—á–µ–≤–∏–π |
| **–†–û–ñ–ï–í–ò–ô** | –ù—ñ–∂–Ω–∏–π, –ø—É–¥—Ä–æ–≤–∏–π | —Å—ñ—Ä–∏–π |
| **–°–Ü–†–ò–ô** | –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∏–π, –±–µ–∑ –∫–æ–ª—å–æ—Ä—É | —Ä–æ–∂–µ–≤–∏–π |

‚ö†Ô∏è –Ø–ö–©–û –ë–ê–ß–ò–® –¢–ï–ü–õ–ò–ô –Ø–°–ö–†–ê–í–ò–ô –ö–û–õ–Ü–† = –ü–û–ú–ê–†–ê–ù–ß–ï–í–ò–ô!
‚ö†Ô∏è –Ø–ö–©–û –ë–ê–ß–ò–® –°–í–Ü–¢–õ–ò–ô –•–û–õ–û–î–ù–ò–ô –ö–û–õ–Ü–† = –ñ–û–í–¢–ò–ô!

---
# ‚ö° –ö–†–ò–¢–ò–ß–ù–û: –ó–ê–í–ñ–î–ò –ó–ê–ü–û–í–ù–Æ–ô identified_product!

–Ø–∫—â–æ —Ç–∏ –í–ü–Ü–ó–ù–ê–í —Ç–æ–≤–∞—Ä –Ω–∞ —Ñ–æ—Ç–æ (confidence >= 0.5), –¢–ò –ó–û–ë–û–í'–Ø–ó–ê–ù–ò–ô –∑–∞–ø–æ–≤–Ω–∏—Ç–∏:

```json
{
  "identified_product": {
    "name": "–ö–æ—Å—Ç—é–º –õ–∞–≥—É–Ω–∞ (–ø–æ–º–∞—Ä–∞–Ω—á–µ–≤–∏–π)",  // –û–ë–û–í'–Ø–ó–ö–û–í–û! –í–ò–ó–ù–ê–ß –ö–û–õ–Ü–† –ó –§–û–¢–û!
    "price": 0,  // 0 = —Ü—ñ–Ω–∞ –±—É–¥–µ –¥—ñ—Å—Ç–∞–Ω–∞ –∑ –ë–î
    "color": "–ø–æ–º–∞—Ä–∞–Ω—á–µ–≤–∏–π"  // –í–ò–ó–ù–ê–ß –ó –§–û–¢–û! –ø–æ–º–∞—Ä–∞–Ω—á–µ–≤–∏–π/–∂–æ–≤—Ç–∏–π/—Ä–æ–∂–µ–≤–∏–π/—Å—ñ—Ä–∏–π
  },
  "confidence": 0.9,
  "reply_to_user": "–¶–µ –Ω–∞—à –ö–æ—Å—Ç—é–º –õ–∞–≥—É–Ω–∞!"
}
```

‚ùå –ù–ï –ü–û–í–ï–†–¢–ê–ô identified_product = null —è–∫—â–æ —Ç–∏ –≤–ø—ñ–∑–Ω–∞–≤ —Ç–æ–≤–∞—Ä!
‚ùå –ù–ï –ß–ï–ö–ê–ô –ø–æ–∫–∏ –¥—ñ–∑–Ω–∞—î—à—Å—è —Ç–æ—á–Ω—É —Ü—ñ–Ω—É ‚Äî –ø–æ—Å—Ç–∞–≤ 0!
‚úÖ –ì–û–õ–û–í–ù–ï ‚Äî –≤–∫–∞–∂–∏ name –¢–û–ß–ù–û —è–∫ –≤ –∫–∞—Ç–∞–ª–æ–∑—ñ!
""")

    return "\n".join(parts)


async def _add_live_catalog_context(ctx: RunContext[AgentDeps]) -> str:
    """
    DYNAMIC system prompt: Load fresh product data from DB.

    Called on EACH request, so prices/stock are always current.
    ALWAYS adds recognition tips from JSON for better identification.
    """
    parts = []

    # 1. Load product prices/names from DB
    try:
        vision_guide = await _load_vision_guide_from_db()
        if vision_guide:
            parts.append(f"\n---\n{vision_guide}")
    except Exception as e:
        logger.warning("Failed to load live catalog: %s", e)
        # Fallback to static JSON for product list
        parts.append(f"\n---\n{_load_vision_guide_from_json()}")
        return "\n".join(parts)

    # 2. ALWAYS add detailed recognition tips from JSON (critical for identification!)
    recognition_tips = _load_recognition_tips_from_json()
    if recognition_tips:
        parts.append(f"\n---\n{recognition_tips}")

    return "\n".join(parts)


def _load_recognition_tips_from_json() -> str:
    """Load detailed recognition tips from JSON file (used ALWAYS, not just fallback)."""
    import json
    from pathlib import Path

    guide_path = Path(__file__).parent.parent.parent.parent / "data" / "vision" / "generated" / "vision_guide.json"

    try:
        with open(guide_path, encoding="utf-8") as f:
            guide = json.load(f)

        data = guide.get("visual_recognition_guide", {})
        products = data.get("products", {})
        detection_rules = data.get("detection_rules", {})

        lines = ["# –î–ï–¢–ê–õ–¨–ù–Ü –û–ó–ù–ê–ö–ò –î–õ–Ø –†–û–ó–ü–Ü–ó–ù–ê–í–ê–ù–ù–Ø\n"]

        # Add key features and tips for each product
        for _sku, product_data in products.items():
            name = product_data.get("name", "Unknown")
            key_features = product_data.get("key_features", {})
            distinction = product_data.get("distinction", {})
            recognition_by_angle = product_data.get("recognition_by_angle", {})

            lines.append(f"## {name}")

            # Fabric type (CRITICAL for plush vs cotton vs leather)
            fabric = key_features.get("fabric")
            if fabric:
                lines.append(f"- **–¢–ö–ê–ù–ò–ù–ê**: {fabric}")

            # Visual markers (CRITICAL)
            markers = key_features.get("markers", [])
            if markers:
                lines.append("- **–ö–õ–Æ–ß–û–í–Ü –û–ó–ù–ê–ö–ò**:")
                for marker in markers:
                    lines.append(f"  - {marker}")

            # Recognition by angle
            if recognition_by_angle:
                front = recognition_by_angle.get("front")
                if front:
                    lines.append(f"- **–í–∏–¥ —Å–ø–µ—Ä–µ–¥—É**: {front}")
                detail = recognition_by_angle.get("detail")
                if detail:
                    lines.append(f"- **–î–µ—Ç–∞–ª—å**: {detail}")

            # Texture description
            texture = product_data.get("texture_description")
            if texture:
                lines.append(f"- **–¢–µ–∫—Å—Ç—É—Ä–∞**: {texture}")

            # CRITICAL: Distinction from similar products
            confused_with = distinction.get("confused_with", [])
            if confused_with:
                lines.append(f"- **‚ö†Ô∏è –ù–ï –ü–õ–£–¢–ê–ô –ó**: {', '.join(confused_with)}")
                how = distinction.get("how_to_distinguish")
                if how:
                    lines.append(f"- **–Ø–ö –í–Ü–î–†–Ü–ó–ù–ò–¢–ò**: {how.strip()}")
                critical = distinction.get("critical_check")
                if critical:
                    lines.append(f"- **üîç –ö–†–ò–¢–ò–ß–ù–ê –ü–ï–†–ï–í–Ü–†–ö–ê**: {critical.strip()}")

            # Unique identifier
            unique = distinction.get("unique_identifier")
            if unique:
                lines.append(f"- **–£–ù–Ü–ö–ê–õ–¨–ù–ê –û–ó–ù–ê–ö–ê**: {unique}")

            lines.append("")

        # Add detection rules
        lines.append("\n# –ü–†–ê–í–ò–õ–ê –®–í–ò–î–ö–û–ì–û –í–ò–ó–ù–ê–ß–ï–ù–ù–Ø")

        by_closure = detection_rules.get("by_closure", {})
        if by_closure:
            lines.append("\n**–ü–æ –∑–∞—Å—Ç—ñ–±—Ü—ñ:**")
            for closure_type, models in by_closure.items():
                lines.append(f"- {closure_type}: {', '.join(models)}")

        by_texture = detection_rules.get("by_texture", {})
        if by_texture:
            lines.append("\n**–ü–æ —Ç–µ–∫—Å—Ç—É—Ä—ñ:**")
            for texture, models in by_texture.items():
                lines.append(f"- {texture}: {', '.join(models)}")

        return "\n".join(lines)

    except Exception as e:
        logger.warning("Failed to load recognition tips from JSON: %s", e)
        return ""


_vision_agent: Agent[AgentDeps, VisionResponse] | None = None


async def _add_image_url(ctx: RunContext[AgentDeps]) -> str:
    """Add image URL to prompt."""
    if ctx.deps.image_url:
        return f"\n[IMAGE_URL: {ctx.deps.image_url}]"
    return ""


def get_vision_agent() -> Agent[AgentDeps, VisionResponse]:
    """
    Get or create vision agent (lazy initialization).

    Architecture:
    - Base prompt: Static algorithm + rules (loaded once)
    - Dynamic prompt: Live catalog data from DB (loaded per request)
    - Image URL: Added per request
    - Model settings: temperature=0.1 (low for deterministic), reasoning=medium
    """
    global _vision_agent
    if _vision_agent is None:
        # Model settings for vision: low temperature for consistency, medium reasoning
        model_settings = {
            "temperature": 0.3,  # Moderate temp for better color recognition
        }
        # Add reasoning effort if supported by model (OpenAI o1/o3, Grok)
        if settings.LLM_REASONING_EFFORT and settings.LLM_REASONING_EFFORT != "none":
            model_settings["reasoning_effort"] = settings.LLM_REASONING_EFFORT

        _vision_agent = Agent(  # type: ignore[call-overload]
            _build_model(),
            deps_type=AgentDeps,
            output_type=VisionResponse,  # PydanticAI 1.23+
            system_prompt=_get_base_vision_prompt(),
            retries=2,
            model_settings=model_settings,  # ‚Üê CRITICAL: temperature + reasoning!
        )
        # Dynamic prompts (called on each request)
        _vision_agent.system_prompt(_add_live_catalog_context)  # ‚Üê LIVE DB DATA!
        _vision_agent.system_prompt(_add_image_url)

        # Tools
        _vision_agent.tool(name="search_products")(_search_products)

        logger.info(
            "üëÅÔ∏è Vision agent initialized: model=%s, temperature=%.1f, reasoning=%s",
            settings.active_llm_model,
            model_settings.get("temperature", 0.3),
            model_settings.get("reasoning_effort", "none"),
        )

    return _vision_agent


# Backward compatibility - removed unused property


# =============================================================================
# RUNNER
# =============================================================================


async def run_vision(
    message: str,
    deps: AgentDeps,
    message_history: list[Any] | None = None,
) -> VisionResponse:
    """
    Run vision agent for photo analysis.

    Args:
        message: User message with photo context
        deps: Dependencies (must have image_url)
        message_history: Previous messages

    Returns:
        Validated VisionResponse
    """
    import asyncio

    agent = get_vision_agent()

    # Build MULTIMODAL input: [text, ImageUrl]
    # PydanticAI requires ImageUrl for vision models to actually SEE the image!
    if deps.image_url:
        # Multimodal input: list of content parts
        user_input: list[str | ImageUrl] = [
            message or "–ê–Ω–∞–ª—ñ–∑—É–π —Ü–µ —Ñ–æ—Ç–æ —Ç–∞ –∑–Ω–∞–π–¥–∏ —Ç–æ–≤–∞—Ä MIRT.",
            ImageUrl(url=deps.image_url),
        ]
        logger.info(
            "üëÅÔ∏è Vision agent starting (MULTIMODAL): image_url=%s",
            deps.image_url[:80] if deps.image_url else "<none>",
        )
    else:
        # No image - cannot proceed with vision analysis
        logger.error("üëÅÔ∏è Vision agent called WITHOUT image! deps.image_url is empty.")
        return VisionResponse(
            reply_to_user="–ù–∞–¥—ñ—à–ª—ñ—Ç—å —Ñ–æ—Ç–æ —Ç–æ–≤–∞—Ä—É, –±—É–¥—å –ª–∞—Å–∫–∞ üì∑",
            confidence=0.0,
            needs_clarification=True,
            clarification_question="–ß–∏ –º–æ–∂–µ—Ç–µ –Ω–∞–¥—ñ—Å–ª–∞—Ç–∏ —Ñ–æ—Ç–æ —Ç–æ–≤–∞—Ä—É?",
        )

    try:
        result = await asyncio.wait_for(
            agent.run(user_input, deps=deps, message_history=message_history),
            timeout=120,  # Increased for slow API tiers
        )
        response = result.output  # output_type param, result.output attr

        # Log identified product
        logger.info(
            "üëÅÔ∏è Vision result: product='%s', confidence=%.2f, needs_clarification=%s",
            response.identified_product.name if response.identified_product else "<none>",
            response.confidence,
            response.needs_clarification,
        )
        return response

    except Exception as e:
        logger.exception("üëÅÔ∏è Vision agent error: %s", e)
        return VisionResponse(
            reply_to_user="–í–∏–±–∞—á—Ç–µ, –Ω–µ –≤–¥–∞–ª–æ—Å—è –ø—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —Ñ–æ—Ç–æ. –°–ø—Ä–æ–±—É–π—Ç–µ –Ω–∞–¥—ñ—Å–ª–∞—Ç–∏ —â–µ —Ä–∞–∑ ü§ç",
            confidence=0.0,
            needs_clarification=True,
            clarification_question="–ß–∏ –º–æ–∂–µ—Ç–µ –Ω–∞–¥—ñ—Å–ª–∞—Ç–∏ —Ñ–æ—Ç–æ —â–µ —Ä–∞–∑ –∞–±–æ –æ–ø–∏—Å–∞—Ç–∏ —Ç–æ–≤–∞—Ä?",
        )
