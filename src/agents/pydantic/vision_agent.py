"""
Vision Agent - Photo analysis specialist.
==========================================
Handles photo identification and product matching.
"""

from __future__ import annotations

import json
import logging
from pathlib import Path
from typing import Any

from openai import AsyncOpenAI
from pydantic_ai import Agent, RunContext
from pydantic_ai.models.openai import OpenAIModel
from pydantic_ai.providers.openai import OpenAIProvider

from src.conf.config import settings
from src.core.prompt_loader import get_system_prompt_text

from .deps import AgentDeps
from .models import VisionResponse


logger = logging.getLogger(__name__)

# Vision guide path
VISION_GUIDE_PATH = Path(__file__).parent.parent.parent.parent / "data" / "vision_guide.json"


def _load_vision_guide() -> str:
    """Load vision recognition guide for better photo analysis."""
    try:
        if VISION_GUIDE_PATH.exists():
            with open(VISION_GUIDE_PATH, encoding="utf-8") as f:
                guide = json.load(f)
            return json.dumps(guide, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.warning("Failed to load vision guide: %s", e)
    return ""


# =============================================================================
# MODEL SETUP
# =============================================================================


def _build_model() -> OpenAIModel:
    """Build OpenAI model."""
    if settings.LLM_PROVIDER == "openai":
        api_key = settings.OPENAI_API_KEY.get_secret_value()
        base_url = "https://api.openai.com/v1"
        model_name = settings.LLM_MODEL_GPT
    else:
        api_key = settings.OPENROUTER_API_KEY.get_secret_value()
        base_url = settings.OPENROUTER_BASE_URL
        model_name = settings.LLM_MODEL_GROK if settings.LLM_PROVIDER == "openrouter" else settings.AI_MODEL

    if not api_key:
        logger.warning("API Key missing for provider %s", settings.LLM_PROVIDER)
        if settings.LLM_PROVIDER == "openai":
             api_key = settings.OPENROUTER_API_KEY.get_secret_value()
             base_url = settings.OPENROUTER_BASE_URL
             model_name = settings.AI_MODEL

    client = AsyncOpenAI(base_url=base_url, api_key=api_key)
    provider = OpenAIProvider(openai_client=client)
    return OpenAIModel(model_name, provider=provider)


# =============================================================================
# VISION AGENT PROMPT
# =============================================================================


async def _search_products(
    ctx: RunContext[AgentDeps],
    query: str,
    category: str | None = None,
) -> str:
    """
    –ó–Ω–∞–π—Ç–∏ —Ç–æ–≤–∞—Ä–∏ –≤ –∫–∞—Ç–∞–ª–æ–∑—ñ.
    
    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π —Ü–µ —â–æ–± –∑–Ω–∞–π—Ç–∏ —Ç–æ–≤–∞—Ä —è–∫–∏–π —Ç–∏ –±–∞—á–∏—à –Ω–∞ —Ñ–æ—Ç–æ.
    –ù–∞–ø—Ä–∏–∫–ª–∞–¥: search_products("—Ä–æ–∂–µ–≤–∞ —Å—É–∫–Ω—è") –∞–±–æ search_products("–∫–æ—Å—Ç—é–º –∑ –ª–∞–º–ø–∞—Å–∞–º–∏")
    """
    products = await ctx.deps.catalog.search_products(query, category)
    
    if not products:
        return "–ù–∞ –∂–∞–ª—å, –∑–∞ –≤–∞—à–∏–º –∑–∞–ø–∏—Ç–æ–º –Ω—ñ—á–æ–≥–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ."
        
    lines = ["–ó–Ω–∞–π–¥–µ–Ω—ñ —Ç–æ–≤–∞—Ä–∏:"]
    for p in products:
        name = p.get("name")
        price = p.get("price")
        sizes = ", ".join(p.get("sizes", []))
        colors = ", ".join(p.get("colors", []))
        sku = p.get("sku", "N/A")
        lines.append(f"- {name} (SKU: {sku}, {price} –≥—Ä–Ω). –†–æ–∑–º—ñ—Ä–∏: {sizes}. –ö–æ–ª—å–æ—Ä–∏: {colors}")
        
    return "\n".join(lines)


def _get_vision_prompt() -> str:
    """Build vision prompt with REAL catalog and recognition guide."""
    # Load full catalog from the same source as support_agent
    full_prompt = get_system_prompt_text("grok")

    # Load vision recognition guide
    vision_guide = _load_vision_guide()

    vision_instructions = """
# VISION AGENT - –ê–Ω–∞–ª—ñ–∑ —Ñ–æ—Ç–æ —Ç–æ–≤–∞—Ä—ñ–≤

–¢–∏ —Å–ø–µ—Ü—ñ–∞–ª—ñ—Å—Ç –∑ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ç–æ–≤–∞—Ä—ñ–≤ MIRT_UA (–û–ª—å–≥–∞).

## –¢–í–û–Ø –ó–ê–î–ê–ß–ê:
1. –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π —Ñ–æ—Ç–æ —è–∫–µ –Ω–∞–¥—ñ—Å–ª–∞–≤ –∫–ª—ñ—î–Ω—Ç
2. –û–ø–∏—à–∏ —â–æ —Ç–∏ –±–∞—á–∏—à (–∫–æ–ª—ñ—Ä, —Ç–∏–ø –æ–¥—è–≥—É, –¥–µ—Ç–∞–ª—ñ)
3. –í–ò–ö–û–†–ò–°–¢–û–í–£–ô —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç `search_products` —â–æ–± –∑–Ω–∞–π—Ç–∏ —Ü–µ–π —Ç–æ–≤–∞—Ä –≤ –±–∞–∑—ñ –¥–∞–Ω–∏—Ö!
   - –®—É–∫–∞–π –∑–∞ –∫–ª—é—á–æ–≤–∏–º–∏ —Å–ª–æ–≤–∞–º–∏ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥ "—Ä–æ–∂–µ–≤–∞ —Å—É–∫–Ω—è", "–∫–æ—Å—Ç—é–º –º–µ—Ä–µ—è")
4. –Ø–∫—â–æ –∑–Ω–∞–π—à–æ–≤ —Ç–æ–≤–∞—Ä - –ø–æ–≤–µ—Ä–Ω–∏ –π–æ–≥–æ –¥–µ—Ç–∞–ª—ñ (–Ω–∞–∑–≤—É, —Ü—ñ–Ω—É, ID)
5. –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π—à–æ–≤ - –∑–∞–ø—Ä–æ–ø–æ–Ω—É–π —Å—Ö–æ–∂—ñ

## –§–û–†–ú–ê–¢ –í–Ü–î–ü–û–í–Ü–î–Ü:
- –Ø–∫—â–æ –∑–Ω–∞–π—à–æ–≤ —Ç–æ–≤–∞—Ä: –æ–ø–∏—à–∏ –π–æ–≥–æ, –¥–∞–π —Ü—ñ–Ω—É, –∑–∞–ø–∏—Ç–∞–π —Ä–æ–∑–º—ñ—Ä
- –Ø–∫—â–æ –Ω–µ –≤–ø–µ–≤–Ω–µ–Ω–∏–π: –∑–∞–ø—Ä–æ–ø–æ–Ω—É–π —Å—Ö–æ–∂—ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏
- –Ø–∫—â–æ –Ω–µ –∑ –∫–∞—Ç–∞–ª–æ–≥—É: –≤–≤—ñ—á–ª–∏–≤–æ –ø–æ—è—Å–Ω–∏ —â–æ –Ω–µ –º–∞—î–º–æ —Ç–∞–∫–æ–≥–æ

## –ó–ê–ë–û–†–û–ù–ï–ù–û:
- –í–∏–≥–∞–¥—É–≤–∞—Ç–∏ —Ç–æ–≤–∞—Ä–∏ —è–∫–∏—Ö –Ω–µ–º–∞—î –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –ø–æ—à—É–∫—É
- –ù–∞–∑–∏–≤–∞—Ç–∏ —Ü—ñ–Ω–∏ "–∑—ñ —Å—Ç–µ–ª—ñ"
- –ü—Ä–æ–ø–æ–Ω—É–≤–∞—Ç–∏ –∫–æ–ª—å–æ—Ä–∏/—Ä–æ–∑–º—ñ—Ä–∏ —è–∫–∏—Ö –Ω–µ–º–∞—î

–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π –£–ö–†–ê–á–ù–°–¨–ö–û–Æ, —Ç–µ–ø–ª–æ —è–∫ –º–µ–Ω–µ–¥–∂–µ—Ä –û–ª—å–≥–∞ ü§ç
"""

    # Build final prompt with vision guide
    if vision_guide:
        return f"{vision_instructions}\n---\n# VISION RECOGNITION GUIDE\n{vision_guide}"
    else:
        return vision_instructions


_vision_agent: Agent[AgentDeps, VisionResponse] | None = None


async def _add_image_url(ctx: RunContext[AgentDeps]) -> str:
    """Add image URL to prompt."""
    if ctx.deps.image_url:
        return f"\n[IMAGE_URL: {ctx.deps.image_url}]"
    return ""


def get_vision_agent() -> Agent[AgentDeps, VisionResponse]:
    """Get or create vision agent (lazy initialization)."""
    global _vision_agent
    if _vision_agent is None:
        _vision_agent = Agent(  # type: ignore[call-overload]
            _build_model(),
            deps_type=AgentDeps,
            output_type=VisionResponse,  # Changed from result_type (PydanticAI 1.23+)
            system_prompt=_get_vision_prompt(),
            retries=2,
        )
        _vision_agent.system_prompt(_add_image_url)
        _vision_agent.tool(name="search_products")(_search_products)
    return _vision_agent


# Backward compatibility - removed unused property


# =============================================================================
# RUNNER
# =============================================================================


async def run_vision(
    message: str,
    deps: AgentDeps,
    message_history: list[Any] | None = None,
) -> VisionResponse:
    """
    Run vision agent for photo analysis.

    Args:
        message: User message with photo context
        deps: Dependencies (must have image_url)
        message_history: Previous messages

    Returns:
        Validated VisionResponse
    """
    import asyncio

    agent = get_vision_agent()

    # Add image context to message
    if deps.image_url and "[IMAGE_URL:" not in message:
        message = f"{message}\n\n[IMAGE_URL: {deps.image_url}]"

    try:
        result = await asyncio.wait_for(
            agent.run(message, deps=deps, message_history=message_history),
            timeout=120,  # Increased for slow API tiers
        )
        return result.output  # output_type param, result.output attr

    except Exception as e:
        logger.exception("Vision agent error: %s", e)
        return VisionResponse(
            reply_to_user="–í–∏–±–∞—á—Ç–µ, –Ω–µ –≤–¥–∞–ª–æ—Å—è –ø—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —Ñ–æ—Ç–æ. –°–ø—Ä–æ–±—É–π—Ç–µ –Ω–∞–¥—ñ—Å–ª–∞—Ç–∏ —â–µ —Ä–∞–∑ ü§ç",
            confidence=0.0,
            needs_clarification=True,
            clarification_question="–ß–∏ –º–æ–∂–µ—Ç–µ –Ω–∞–¥—ñ—Å–ª–∞—Ç–∏ —Ñ–æ—Ç–æ —â–µ —Ä–∞–∑ –∞–±–æ –æ–ø–∏—Å–∞—Ç–∏ —Ç–æ–≤–∞—Ä?",
        )
