"""
Support/Sales Agent - Prompts loaded from data/prompts/states/ and data/prompts/system/
=======================================================
MIRT AI AGENT v7.0 - "–°–æ—Ñ—ñ—è"

IDENTITY (BLOCK 2):
- role: "AI-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –º–∞–≥–∞–∑–∏–Ω—É –¥–∏—Ç—è—á–æ–≥–æ –æ–¥—è–≥—É MIRT"
- agent_name: "–°–æ—Ñ—ñ—è"
- personality: "–ñ–∏–≤–∞ –ª—é–¥–∏–Ω–∞: –º–æ–∂—É –ø–µ—Ä–µ–ø–∏—Ç–∞—Ç–∏, –º–æ–∂—É —á–µ—Å–Ω–æ —Å–∫–∞–∑–∞—Ç–∏, —è–∫—â–æ –Ω–µ –≤–ø–µ–≤–Ω–µ–Ω–∞."

IMMUTABLE_RULES:
- [P0] –ú–æ–≤–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –¢–Ü–õ–¨–ö–ò —É–∫—Ä–∞—ó–Ω—Å—å–∫–∞
- [P0] –ó–ê–ë–û–†–û–ù–ï–ù–û –≤–∏–≥–∞–¥—É–≤–∞—Ç–∏ —Ç–æ–≤–∞—Ä–∏, –∫–æ–ª—å–æ—Ä–∏, —Ä–æ–∑–º—ñ—Ä–∏, —Ü—ñ–Ω–∏ - –¢–Ü–õ–¨–ö–ò –∑ CATALOG
- [P0] –ú–∞–∫—Å–∏–º—É–º 900 —Å–∏–º–≤–æ–ª—ñ–≤ —É –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
- [P0] –ó–ê–õ–Ü–ó–û–ë–ï–¢–û–ù–ù–ï –ü–†–ê–í–ò–õ–û: –ù–∞ –º–µ–∂–∞—Ö (120, 131, 143, 155 —Å–º) –ù–ï –ø–µ—Ä–µ—Ö–æ–¥–∏–º–æ –≤ –±—ñ–ª—å—à–∏–π —Ä–æ–∑–º—ñ—Ä!

OUTPUT_CONTRACT:
- event: simple_answer/clarifying_question/multi_option/escalation/end_smalltalk
- messages: [{type: "text", content: "..."}]
- products: [{id, name, price, size, color, photo_url}] - –¢–Ü–õ–¨–ö–ò –∑ CATALOG!
- metadata: {session_id, current_state, intent, escalation_level}
"""

from __future__ import annotations

import logging
from typing import Any

from openai import AsyncOpenAI
from pydantic_ai import Agent, RunContext
from pydantic_ai.models.openai import OpenAIChatModel
from pydantic_ai.providers.openai import OpenAIProvider

from src.conf.config import settings
from src.conf.payment_config import format_requisites_multiline
from src.core.human_responses import get_human_response
from src.core.prompt_registry import registry

from .deps import AgentDeps
from .models import (
    EscalationInfo,
    MessageItem,
    ResponseMetadata,
    SupportResponse,
)


logger = logging.getLogger(__name__)


def _get_timeout_response() -> str:
    """Get human-like timeout response."""
    return get_human_response("timeout")


def _get_error_response() -> str:
    """Get human-like error response."""
    return get_human_response("error")


# =============================================================================
# MODEL SETUP (Lazy initialization)
# =============================================================================

_model: OpenAIChatModel | None = None
_agent: Agent[AgentDeps, SupportResponse] | None = None


def _get_model() -> OpenAIChatModel:
    """Get or create OpenAI model (lazy initialization)."""
    global _model
    if _model is None:
        if settings.LLM_PROVIDER == "openai":
            api_key = settings.OPENAI_API_KEY.get_secret_value()
            base_url = "https://api.openai.com/v1"
            model_name = settings.LLM_MODEL_GPT
        else:
            api_key = settings.OPENROUTER_API_KEY.get_secret_value()
            base_url = settings.OPENROUTER_BASE_URL
            model_name = (
                settings.LLM_MODEL_GROK
                if settings.LLM_PROVIDER == "openrouter"
                else settings.AI_MODEL
            )

        if not api_key:
            # Fallback or error
            logger.warning("API Key missing for provider %s", settings.LLM_PROVIDER)
            # Try OpenRouter as fallback if OpenAI missing
            if settings.LLM_PROVIDER == "openai":
                api_key = settings.OPENROUTER_API_KEY.get_secret_value()
                base_url = settings.OPENROUTER_BASE_URL
                model_name = settings.AI_MODEL

        client = AsyncOpenAI(
            base_url=base_url,
            api_key=api_key,
        )
        provider = OpenAIProvider(openai_client=client)
        _model = OpenAIChatModel(model_name, provider=provider)
    return _model


def _get_base_prompt() -> str:
    """Get system prompt (lazy load)."""
    return registry.get("system.main").content


async def _add_manager_snippets(ctx: RunContext[AgentDeps]) -> str:
    """Inject manager canned templates (editable via prompt file)."""
    try:
        content = registry.get("system.snippets").content
        logger.info(
            "üìã Manager snippets injected (%d chars, version=%s)",
            len(content),
            registry.get("system.snippets").metadata.get("version", "unknown"),
        )
        return "\n--- –®–ê–ë–õ–û–ù–ò –ú–ï–ù–ï–î–ñ–ï–†–ê ---\n" + content
    except (FileNotFoundError, ValueError) as e:
        logger.warning("Manager snippets not found: %s", e)
        return ""


async def _add_payment_requisites(ctx: RunContext[AgentDeps]) -> str:
    """Inject canonical payment requisites to avoid LLM hallucinations."""
    # –ù–ï –ø–æ–∫–∞–∑—É–π —Ç–µ—Ö–Ω—ñ—á–Ω—ñ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∫–ª—ñ—î–Ω—Ç—É - –ø—Ä–æ—Å—Ç–æ —Ä–µ–∫–≤—ñ–∑–∏—Ç–∏
    return format_requisites_multiline()


# =============================================================================
# DYNAMIC PROMPTS (registered via function)
# =============================================================================


async def _add_state_context(ctx: RunContext[AgentDeps]) -> str:
    """Add current state and customer context to prompt."""
    deps = ctx.deps

    lines = [
        "\n--- –ö–û–ù–¢–ï–ö–°–¢ –°–ï–°–Ü–á ---",
        f"Session ID: {deps.session_id}",
        f"–ü–æ—Ç–æ—á–Ω–∏–π —Å—Ç–∞–Ω: {deps.current_state}",
        f"–ö–∞–Ω–∞–ª: {deps.channel}",
    ]

    if any([deps.customer_name, deps.customer_phone, deps.customer_city]):
        lines.append("\n--- –î–ê–ù–Ü –ö–õ–Ü–Ñ–ù–¢–ê ---")
        lines.append(deps.get_customer_data_summary())

    if deps.selected_products:
        lines.append("\n--- –í–ò–ë–†–ê–ù–Ü –¢–û–í–ê–†–ò ---")
        for p in deps.selected_products[:3]:
            lines.append(f"- {p.get('name', '–¢–æ–≤–∞—Ä')}: {p.get('price', 0)} –≥—Ä–Ω")

    return "\n".join(lines)


async def _add_memory_context(ctx: RunContext[AgentDeps]) -> str:
    """
    Add memory context (Titans-like) to prompt.

    This injects persistent profile and fluid facts from memory system.
    Populated by memory_context_node before agent execution.
    """
    deps = ctx.deps

    # Use pre-formatted memory context if available
    memory_prompt = deps.get_memory_context_prompt()

    if memory_prompt:
        logger.debug(
            "üìö Memory context injected (%d chars)",
            len(memory_prompt),
        )
        return f"\n{memory_prompt}"

    return ""


async def _add_image_context(ctx: RunContext[AgentDeps]) -> str:
    """Add image analysis instructions if image present."""
    if not ctx.deps.has_image:
        return ""

    return """
--- –§–û–¢–û –í–Ü–î –ö–õ–Ü–Ñ–ù–¢–ê ---
–í–ê–ñ–õ–ò–í–û: –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á –Ω–∞–¥—ñ—Å–ª–∞–≤ –§–û–¢–û!
1. –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π —Ñ–æ—Ç–æ —Ç–∞ –≤–∏–∑–Ω–∞—á —Ç–æ–≤–∞—Ä –∑ EMBEDDED CATALOG
2. –Ø–∫—â–æ –∑–Ω–∞–π—à–æ–≤ —Ç–æ–≤–∞—Ä - –û–î–†–ê–ó–£ –¥–∞–π —Ü—ñ–Ω—É —Ç–∞ –∑–∞–ø—Ä–æ–ø–æ–Ω—É–π —Ä–æ–∑–º—ñ—Ä
3. Intent –º–∞—î –±—É—Ç–∏ PHOTO_IDENT
4. –ù–µ –ø–∏—Ç–∞–π '—â–æ –≤–∞—Å —Ü—ñ–∫–∞–≤–∏—Ç—å' - –≤—ñ–¥–ø–æ–≤—ñ–¥–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ!
"""


async def _add_state_instructions(ctx: RunContext[AgentDeps]) -> str:
    """
    Add state-specific behavioral instructions.

    QUALITY: –ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç –ø—Ä–æ–º–ø—Ç—ñ–≤:
    1. state_specific_prompt –∑ deps (injected by agent_node)
    2. –ü—Ä–æ–º–ø—Ç –∑ registry (state.STATE_X_Y)
    """
    deps = ctx.deps
    state = deps.current_state

    # QUALITY: Prefer injected state_specific_prompt (from state_prompts.py)
    if deps.state_specific_prompt:
        logger.info(
            "üìã Using injected state prompt for %s (%d chars)",
            state,
            len(deps.state_specific_prompt),
        )
        return f"\n--- –Ü–ù–°–¢–†–£–ö–¶–Ü–Ø –î–õ–Ø –°–¢–ê–ù–£ ({state}) ---\n{deps.state_specific_prompt}"

    # Fallback to registry
    try:
        prompt = registry.get(f"state.{state}")
        logger.info(
            "üìã Loaded state prompt from registry for %s (%d chars)", state, len(prompt.content)
        )
        return f"\n--- –Ü–ù–°–¢–†–£–ö–¶–Ü–Ø –î–õ–Ø –°–¢–ê–ù–£ ({state}) ---\n{prompt.content}"
    except (FileNotFoundError, ValueError) as e:
        logger.warning("No prompt found for state: %s (%s)", state, e)
        return ""


# =============================================================================
# TOOLS (registered via function)
# =============================================================================


async def _get_size_recommendation(
    ctx: RunContext[AgentDeps],
    height_cm: int,
) -> str:
    """
    –û—Ç—Ä–∏–º–∞—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—é —Ä–æ–∑–º—ñ—Ä—É –∑–∞ –∑—Ä–æ—Å—Ç–æ–º.

    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î —Ñ–æ—Ä–º–∞—Ç: "–í–∞–º —á—É–¥–æ–≤–æ –ø—ñ–¥—ñ–π–¥–µ –Ω–∞—à —Ä–æ–∑–º—ñ—Ä {size}, –≤—ñ–Ω —ñ–¥–µ —Ñ–∞–∫—Ç–∏—á–Ω–æ –¥–æ –∑—Ä–æ—Å—Ç—É {max_height} —Å–ºüëå"

    –ó–ê–õ–Ü–ó–û–ë–ï–¢–û–ù–ù–ï –ü–†–ê–í–ò–õ–û: –ù–∞ –º–µ–∂–∞—Ö (120, 131, 143, 155) –ù–ï –ø–µ—Ä–µ—Ö–æ–¥–∏–º–æ –≤ –±—ñ–ª—å—à–∏–π —Ä–æ–∑–º—ñ—Ä!
    
    –õ—ñ–Ω—ñ–π–∫–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ—Å—Ç—ñ:
    - 110-120 —Å–º –≤–∫–ª—é—á–Ω–æ ‚Üí 110-116
    - 121-131 —Å–º –≤–∫–ª—é—á–Ω–æ ‚Üí 122-128
    - 132-143 —Å–º –≤–∫–ª—é—á–Ω–æ ‚Üí 134-140
    - 144-155 —Å–º –≤–∫–ª—é—á–Ω–æ ‚Üí 146-152
    - 156-168 —Å–º –≤–∫–ª—é—á–Ω–æ ‚Üí 158-164
    """
    from src.agents.langgraph.nodes.utils import get_size_recommendation_text
    from src.agents.langgraph.nodes.helpers.size_parsing import height_to_size

    # Edge cases
    if height_cm < 80:
        return "–ù–∞—à –Ω–∞–π–º–µ–Ω—à–∏–π —Ä–æ–∑–º—ñ—Ä —Ä–æ–∑—Ä–∞—Ö–æ–≤–∞–Ω–∏–π –Ω–∞ –∑—Ä—ñ—Å—Ç –≤—ñ–¥ 80 —Å–º. –Ø–∫—â–æ –º–∞–ª—é–∫ —Ç—Ä–æ—Ö–∏ –º–µ–Ω—à–∏–π - –º–æ–∂–Ω–∞ –≤–∑—è—Ç–∏ 80-92, –≤—ñ–Ω —Å—è–¥–µ –≤—ñ–ª—å–Ω—ñ—à–µ —ñ –±—É–¥–µ –Ω–∞ –≤–∏—Ä—ñ—Å—Ç ü§ç"

    if height_cm > 168:
        return "–ù–∞—à –Ω–∞–π–±—ñ–ª—å—à–∏–π —Ä–æ–∑–º—ñ—Ä 158-164 –Ω–∞ –∑—Ä—ñ—Å—Ç –¥–æ 168 —Å–º. –Ø–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ –±—ñ–ª—å—à–µ - –Ω–∞–ø–∏—à—ñ—Ç—å, —è —É—Ç–æ—á–Ω—é —É –∫–æ–ª–µ–≥, —á–∏ —î –≤–∞—Ä—ñ–∞–Ω—Ç–∏."

    # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ height_to_size –∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—é –ª–æ–≥—ñ–∫–æ—é –≥—Ä–∞–Ω–∏—á–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å
    size_label = height_to_size(height_cm)
    return get_size_recommendation_text(size_label)


async def _check_customer_data(ctx: RunContext[AgentDeps]) -> str:
    """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —è–∫—ñ –¥–∞–Ω—ñ –∫–ª—ñ—î–Ω—Ç–∞ –≤–∂–µ –∑—ñ–±—Ä–∞–Ω—ñ."""
    deps = ctx.deps
    collected, missing = [], []

    if deps.customer_name:
        collected.append(f"–ü–Ü–ë: {deps.customer_name}")
    else:
        missing.append("–ü–Ü–ë")

    if deps.customer_phone:
        collected.append(f"–¢–µ–ª–µ—Ñ–æ–Ω: {deps.customer_phone}")
    else:
        missing.append("–¢–µ–ª–µ—Ñ–æ–Ω")

    if deps.customer_city:
        collected.append(f"–ú—ñ—Å—Ç–æ: {deps.customer_city}")
    else:
        missing.append("–ú—ñ—Å—Ç–æ")

    if deps.customer_nova_poshta:
        collected.append(f"–í—ñ–¥–¥—ñ–ª–µ–Ω–Ω—è –ù–ü: {deps.customer_nova_poshta}")
    else:
        missing.append("–í—ñ–¥–¥—ñ–ª–µ–Ω–Ω—è –ù–ü")

    result = []
    if collected:
        result.append(f"–ó—ñ–±—Ä–∞–Ω–æ: {', '.join(collected)}")
    if missing:
        result.append(f"–ü–æ—Ç—Ä—ñ–±–Ω–æ —â–µ: {', '.join(missing)}")

    return "\n".join(result) if result else "–î–∞–Ω—ñ –Ω–µ –∑—ñ–±—Ä–∞–Ω—ñ"


async def _get_order_summary(ctx: RunContext[AgentDeps]) -> str:
    """–û—Ç—Ä–∏–º–∞—Ç–∏ –ø—ñ–¥—Å—É–º–æ–∫ –∑–∞–º–æ–≤–ª–µ–Ω–Ω—è."""
    products = ctx.deps.selected_products

    if not products:
        return "–¢–æ–≤–∞—Ä–∏ —â–µ –Ω–µ –≤–∏–±—Ä–∞–Ω—ñ"

    lines = ["–ó–∞–º–æ–≤–ª–µ–Ω–Ω—è:"]
    total = 0.0

    for p in products:
        name = p.get("name", "–¢–æ–≤–∞—Ä")
        price = p.get("price", 0)
        size = p.get("size", "")

        line = f"- {name}"
        if size:
            line += f" (—Ä–æ–∑–º—ñ—Ä {size})"
        line += f": {price} –≥—Ä–Ω"

        lines.append(line)
        total += price

    lines.append(f"\n–†–∞–∑–æ–º: {total} –≥—Ä–Ω")
    return "\n".join(lines)


async def _search_products(
    ctx: RunContext[AgentDeps],
    query: str,
    category: str | None = None,
) -> str:
    """
    –ó–Ω–∞–π—Ç–∏ —Ç–æ–≤–∞—Ä–∏ –≤ –∫–∞—Ç–∞–ª–æ–∑—ñ.

    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π —Ü–µ –∫–æ–ª–∏ –∫–ª—ñ—î–Ω—Ç –ø–∏—Ç–∞—î –ø—Ä–æ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –∞–±–æ –ø—Ä–æ—Å–∏—Ç—å –ø–æ–∫–∞–∑–∞—Ç–∏ —Ç–æ–≤–∞—Ä–∏.
    """
    products = await ctx.deps.catalog.search_products(query, category)

    if not products:
        return get_human_response("not_found")

    lines = ["–ó–Ω–∞–π–¥–µ–Ω—ñ —Ç–æ–≤–∞—Ä–∏:"]
    for p in products:
        name = p.get("name")
        price = p.get("price")
        sizes = ", ".join(p.get("sizes", []))
        colors = ", ".join(p.get("colors", []))
        lines.append(f"- {name} ({price} –≥—Ä–Ω). –†–æ–∑–º—ñ—Ä–∏: {sizes}. –ö–æ–ª—å–æ—Ä–∏: {colors}")

    return "\n".join(lines)


# =============================================================================
# REGISTRATION FUNCTIONS
# =============================================================================


def _register_dynamic_prompts(agent: Agent[AgentDeps, SupportResponse]) -> None:
    """Register dynamic system prompts with the agent."""
    agent.system_prompt(_add_manager_snippets)
    agent.system_prompt(_add_payment_requisites)
    agent.system_prompt(_add_state_context)
    agent.system_prompt(_add_memory_context)  # Titans-like memory context
    agent.system_prompt(_add_image_context)
    agent.system_prompt(_add_state_instructions)


def _register_tools(agent: Agent[AgentDeps, SupportResponse]) -> None:
    """Register tools with the agent using decorator syntax."""
    agent.tool(name="get_size_recommendation")(_get_size_recommendation)
    agent.tool(name="check_customer_data")(_check_customer_data)
    agent.tool(name="get_order_summary")(_get_order_summary)
    agent.tool(name="search_products")(_search_products)


# =============================================================================
# AGENT FACTORY (Lazy initialization)
# =============================================================================


def get_support_agent() -> Agent[AgentDeps, SupportResponse]:
    """Get or create the support agent (lazy initialization)."""
    global _agent
    if _agent is None:
        _agent = Agent(  # type: ignore[call-overload]
            _get_model(),
            deps_type=AgentDeps,
            output_type=SupportResponse,  # Changed from result_type (PydanticAI 1.23+)
            system_prompt=_get_base_prompt(),
            retries=2,
        )
        _register_dynamic_prompts(_agent)
        _register_tools(_agent)

    return _agent


# =============================================================================
# RUNNER FUNCTION (for LangGraph nodes)
# =============================================================================


async def run_support(
    message: str,
    deps: AgentDeps,
    message_history: list[Any] | None = None,
) -> SupportResponse:
    """
    Run support agent and return structured response.

    This is what LangGraph nodes call.

    Args:
        message: User message
        deps: Injected dependencies
        message_history: Previous messages (Pydantic AI format)

    Returns:
        Validated SupportResponse
    """
    import asyncio

    agent = get_support_agent()

    try:
        result = await asyncio.wait_for(
            agent.run(
                message,
                deps=deps,
                message_history=message_history,
            ),
            timeout=45,  # Reduced to cap max response time
        )

        # result.output is the typed output (SupportResponse)
        # Note: output_type param (not result_type) but result.output (not result.response)
        return result.output

    except TimeoutError:
        logger.error("Support agent timeout for session %s", deps.session_id)
        return SupportResponse(
            event="escalation",
            messages=[MessageItem(content=_get_timeout_response())],
            metadata=ResponseMetadata(
                session_id=deps.session_id or "",
                current_state=deps.current_state or "STATE_0_INIT",
                intent="UNKNOWN_OR_EMPTY",
                escalation_level="L1",
            ),
            escalation=EscalationInfo(reason="LLM_TIMEOUT"),
        )

    except Exception as e:
        logger.exception("Support agent error: %s", e)
        return SupportResponse(
            event="escalation",
            messages=[MessageItem(content=_get_error_response())],
            metadata=ResponseMetadata(
                session_id=deps.session_id or "",
                current_state=deps.current_state or "STATE_0_INIT",
                intent="UNKNOWN_OR_EMPTY",
                escalation_level="L2",
            ),
            escalation=EscalationInfo(reason=f"AGENT_ERROR: {str(e)[:100]}"),
        )
