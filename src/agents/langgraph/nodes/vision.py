"""
Vision Node - Photo processing.
===============================
Handles image identification and product matching.
Uses run_vision directly (NOT through generic runner).

REFACTORED for clarity:
- _extract_products() - get products from VisionResponse
- _build_vision_messages() - build multi-bubble response
- vision_node() - main orchestrator (simple!)
"""

from __future__ import annotations

import logging
import time
from typing import TYPE_CHECKING, Any

from src.agents.pydantic.deps import create_deps_from_state
from src.agents.pydantic.vision_agent import run_vision
from src.core.state_machine import State
from src.services.catalog_service import CatalogService
from src.services.observability import log_agent_step, log_trace, track_metric

from .utils import (
    extract_height_from_text,
    get_size_and_price_for_height,
    image_msg,
    text_msg,
)


if TYPE_CHECKING:
    from collections.abc import Callable

    from src.agents.pydantic.models import VisionResponse


logger = logging.getLogger(__name__)


# =============================================================================
# HELPER FUNCTIONS (extracted for clarity)
# =============================================================================


async def _enrich_product_from_db(product_name: str, color: str | None = None) -> dict[str, Any] | None:
    """Lookup product in DB by name (and color if provided) and return enriched data.

    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è, –∫–æ–ª–∏ Vision –ø–æ–≤–µ—Ä–Ω—É–≤ –Ω–∞–∑–≤—É –±–µ–∑ —Ü—ñ–Ω–∏/—Ñ–æ—Ç–æ.
    –í–ê–ñ–õ–ò–í–û: –Ø–∫—â–æ —î –∫–æ–ª—ñ—Ä - —à—É–∫–∞—î –∑ –∫–æ–ª—å–æ—Ä–æ–º –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ match!
    """
    try:
        catalog = CatalogService()
        
        # –Ø–∫—â–æ –∫–æ–ª—ñ—Ä –≤–∂–µ –≤ –Ω–∞–∑–≤—ñ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥ "–ö–æ—Å—Ç—é–º –†–∏—Ç–º (—Ä–æ–∂–µ–≤–∏–π)") - –Ω–µ –¥—É–±–ª—é—î–º–æ
        search_query = product_name
        if color and f"({color})" not in product_name.lower() and color.lower() not in product_name.lower():
            # –°–ø—Ä–æ–±—É—î–º–æ –∑–Ω–∞–π—Ç–∏ —Ç–æ—á–Ω–∏–π match –∑ –∫–æ–ª—å–æ—Ä–æ–º
            search_query = f"{product_name} ({color})"
        
        results = await catalog.search_products(query=search_query, limit=5)
        
        # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π—à–ª–∏ –∑ –ø–æ–≤–Ω–æ—é –Ω–∞–∑–≤–æ—é - —Å–ø—Ä–æ–±—É—î–º–æ –±–∞–∑–æ–≤—É –Ω–∞–∑–≤—É –±–µ–∑ –∫–æ–ª—å–æ—Ä—É
        if not results and "(" in product_name:
            base_name = product_name.split("(")[0].strip()
            logger.debug("Retry search with base name: '%s'", base_name)
            results = await catalog.search_products(query=base_name, limit=5)
        
        # –Ø–∫—â–æ —î –∫–æ–ª—ñ—Ä - —à—É–∫–∞—î–º–æ —Ç–æ–≤–∞—Ä –∑ —Ü–∏–º –∫–æ–ª—å–æ—Ä–æ–º
        product = None
        if color and results:
            for p in results:
                p_name = p.get("name", "").lower()
                if color.lower() in p_name:
                    product = p
                    break
        
        # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π—à–ª–∏ –∑ –∫–æ–ª—å–æ—Ä–æ–º - –±–µ—Ä–µ–º–æ –ø–µ—Ä—à–∏–π
        if not product and results:
            product = results[0]
        
        if product:
            price_display = CatalogService.format_price_display(product)
            # Try multiple possible column names for photo URL
            photo_url = (
                product.get("photo_url") 
                or product.get("image_url") 
                or product.get("photo") 
                or product.get("image")
                or ""
            )
            logger.info(
                "üì¶ Enriched from DB: %s (color=%s) -> %s, photo=%s",
                product_name, color, price_display, 
                photo_url[:50] if photo_url else "<no photo>"
            )
            return {
                "id": product.get("id", 0),
                "name": product.get("name", product_name),
                "price": CatalogService.get_price_for_size(product),
                "price_display": price_display,
                "color": (product.get("colors") or [""])[0]
                if isinstance(product.get("colors"), list)
                else product.get("colors", ""),
                "photo_url": photo_url,
                "description": product.get("description", ""),
            }
    except Exception as e:
        logger.warning("DB enrichment failed: %s", e)
    return None


def _extract_products(
    response: VisionResponse,
    existing: list[dict[str, Any]],
) -> list[dict[str, Any]]:
    """Extract products from VisionResponse into state format.
    
    Logic:
    - If confidence >= 85% ‚Üí show ONLY identified product (no alternatives)
    - If confidence < 85% ‚Üí show identified + alternatives for user to choose
    """
    products = list(existing)
    confidence = response.confidence or 0.0

    if response.identified_product:
        products = [response.identified_product.model_dump()]
        logger.info("Vision identified: %s (confidence=%.0f%%)", 
                   response.identified_product.name, confidence * 100)

    # Only show alternatives if NOT confident enough
    # High confidence = we know what it is, no need to confuse user with options
    if response.alternative_products and confidence < 0.85:
        products.extend([p.model_dump() for p in response.alternative_products])
        logger.info("Vision alternatives: %d (showing because confidence < 85%%)", 
                   len(response.alternative_products))
    elif response.alternative_products:
        logger.info("Vision: skipping %d alternatives (confidence=%.0f%% >= 85%%)",
                   len(response.alternative_products), confidence * 100)

    return products


def _build_vision_messages(
    response: VisionResponse,
    previous_messages: list[Any],
    vision_greeted: bool,
    user_message: str = "",
) -> list[dict[str, str]]:
    """
    Build multi-bubble assistant response from VisionResponse.

    Message order (if product found):
    1. Greeting (if first message): –±–µ–∑ –∑–≥–∞–¥–∫–∏ –ø—Ä–æ —Ñ–æ—Ç–æ/–±–æ—Ç–∞
    2. Product: –Ω–∞–∑–≤–∞ + –∫–æ–ª—ñ—Ä
    3. –¶—ñ–Ω–∞ (—è–∫—â–æ –∑—Ä—ñ—Å—Ç –≤–∂–µ –≤–∫–∞–∑–∞–Ω–æ) –ê–ë–û –∑–∞–ø–∏—Ç –ø—Ä–æ –∑—Ä—ñ—Å—Ç
    4. Photo: [product image]

    If product NOT found:
    - Clarification question from LLM or fallback
    """
    messages: list[dict[str, str]] = []

    # 1. Greeting: –æ–¥–∏–Ω —Ä–∞–∑ –Ω–∞ –ø–µ—Ä—à—É —Ñ–æ—Ç–æ-–≤–∑–∞—î–º–æ–¥—ñ—é –≤ —Å–µ—Å—ñ—ó
    if not vision_greeted:
        messages.append(text_msg("–í—ñ—Ç–∞—é üéÄ –ó –≤–∞–º–∏ MIRT_UA, –º–µ–Ω–µ–¥–∂–µ—Ä –û–ª—å–≥–∞."))

    # 2. Product highlight –ë–ï–ó –¶–Ü–ù–ò (—Ü—ñ–Ω–∞ —Ç—ñ–ª—å–∫–∏ –ø—ñ—Å–ª—è –∑—Ä–æ—Å—Ç—É!)
    # –ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ reply_to_user –≤—ñ–¥ LLM - –±—É–¥—É—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å —Å–∞–º—ñ –∑ —Ç–æ—á–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏ –∑ –ë–î
    product = response.identified_product
    if product:
        # –ë–ê–ë–õ–ê 2: –ù–∞–∑–≤–∞ —Ç–æ–≤–∞—Ä—É + –∫–æ–ª—ñ—Ä (–ë–ï–ó –¶–Ü–ù–ò!)
        # –¶—ñ–Ω–∞ –±—É–¥–µ –ø–æ–∫–∞–∑–∞–Ω–∞ —Ç—ñ–ª—å–∫–∏ –ø—ñ—Å–ª—è —Ç–æ–≥–æ —è–∫ –∫–ª—ñ—î–Ω—Ç –≤–∫–∞–∂–µ –∑—Ä—ñ—Å—Ç
        product_name = product.name
        
        # Check if color is already in the name (e.g., "–ö–æ—Å—Ç—é–º –†–∏—Ç–º (—Ä–æ–∂–µ–≤–∏–π)")
        # to avoid duplication like "–ö–æ—Å—Ç—é–º –†–∏—Ç–º (—Ä–æ–∂–µ–≤–∏–π) —É –∫–æ–ª—å–æ—Ä—ñ —Ä–æ–∂–µ–≤–∏–π"
        color_already_in_name = (
            product.color and 
            product.color.lower() in product_name.lower()
        )
        
        if color_already_in_name:
            # Color is in name - just use the name
            message_text = f"–¶–µ –Ω–∞—à {product_name} üíõ"
        elif product.color:
            # Color NOT in name - add it
            message_text = f"–¶–µ –Ω–∞—à {product_name} —É –∫–æ–ª—å–æ—Ä—ñ {product.color} üíõ"
        else:
            # No color info at all
            message_text = f"–¶–µ –Ω–∞—à {product_name} üíõ"
        
        messages.append(text_msg(message_text))
        
        # –ë–ê–ë–õ–ê 3: –Ø–∫—â–æ –∑—Ä—ñ—Å—Ç –≤–∂–µ –≤ —Ç–µ–∫—Å—Ç—ñ (—Ñ–æ—Ç–æ + —Ç–µ–∫—Å—Ç —Ä–∞–∑–æ–º) - –ø–æ–∫–∞–∑—É—î–º–æ —Ü—ñ–Ω—É –æ–¥—Ä–∞–∑—É!
        # –Ü–Ω–∞–∫—à–µ –ø–∏—Ç–∞—î–º–æ –∑—Ä—ñ—Å—Ç, —ñ agent_node –æ–±—Ä–æ–±–∏—Ç—å –≤—ñ–¥–ø–æ–≤—ñ–¥—å
        height = extract_height_from_text(user_message)
        if height:
            # –ó—Ä—ñ—Å—Ç —î –≤ —Ç–µ–∫—Å—Ç—ñ —Ä–∞–∑–æ–º –∑ —Ñ–æ—Ç–æ - –ø–æ–∫–∞–∑—É—î–º–æ —Ü—ñ–Ω—É –æ–¥—Ä–∞–∑—É!
            size_label, price = get_size_and_price_for_height(height)
            messages.append(text_msg(f"–ù–∞ {height} —Å–º –ø—ñ–¥—ñ–π–¥–µ —Ä–æ–∑–º—ñ—Ä {size_label}"))
            messages.append(text_msg(f"–¶—ñ–Ω–∞ {price} –≥—Ä–Ω"))
            messages.append(text_msg("–û—Ñ–æ—Ä–º–ª—é—î–º–æ? üå∏"))
        else:
            # –¢—ñ–ª—å–∫–∏ —Ñ–æ—Ç–æ –±–µ–∑ –∑—Ä–æ—Å—Ç—É - –ø–∏—Ç–∞—î–º–æ
            messages.append(text_msg("–ù–∞ —è–∫–∏–π –∑—Ä—ñ—Å—Ç –ø—ñ–¥–∫–∞–∑–∞—Ç–∏? üå∏"))

        # –ë–ê–ë–õ–ê 4: –§–æ—Ç–æ —Ç–æ–≤–∞—Ä—É (—è–∫—â–æ —î)
        if product.photo_url:
            messages.append(image_msg(product.photo_url))

    # 4. Clarification (—Ç—ñ–ª—å–∫–∏ —è–∫—â–æ –ù–ï –≤–ø—ñ–∑–Ω–∞–ª–∏ —Ç–æ–≤–∞—Ä)
    elif response.clarification_question:
        messages.append(text_msg(response.clarification_question.strip()))
    elif response.needs_clarification:
        messages.append(text_msg("–ù–µ –º–æ–∂—É —Ç–æ—á–Ω–æ –≤–∏–∑–Ω–∞—á–∏—Ç–∏ –º–æ–¥–µ–ª—å. –ü—ñ–¥–∫–∞–∂—ñ—Ç—å, –±—É–¥—å –ª–∞—Å–∫–∞, —â–æ —Ü–µ –∑–∞ —Ç–æ–≤–∞—Ä? ü§ç"))

    # 5. Fallback
    if not messages:
        messages.append(
            text_msg(
                "–ù–µ –≤–ø—ñ–∑–Ω–∞–ª–∞ –º–æ–¥–µ–ª—å –Ω–∞ —Ñ–æ—Ç–æ. –ú–æ–∂—É –ø–æ–∫–∞–∑–∞—Ç–∏ –ø–æ–ø—É–ª—è—Ä–Ω—ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏ - —Å–∫–∞–∂—ñ—Ç—å, —è–∫–∏–π —Ç–∏–ø –∞–±–æ –∫–æ–ª—ñ—Ä —Ü—ñ–∫–∞–≤–∏—Ç—å, —ñ –Ω–∞ —è–∫–∏–π –∑—Ä—ñ—Å—Ç —à—É–∫–∞—î—Ç–µ."
            )
        )

    return messages


# =============================================================================
# MAIN NODE
# =============================================================================


async def vision_node(
    state: dict[str, Any],
    runner: Callable[..., Any] | None = None,  # Kept for signature compatibility
) -> dict[str, Any]:
    """
    Process photo and identify product.

    This node:
    1. Extracts user message and image_url from state
    2. Calls run_vision (PydanticAI vision agent)
    3. Builds multi-bubble response using helper functions
    4. Updates state with results

    Args:
        state: Current conversation state
        runner: IGNORED - uses run_vision directly

    Returns:
        State update with identified products
    """
    start_time = time.perf_counter()
    session_id = state.get("session_id", state.get("metadata", {}).get("session_id", ""))
    messages = state.get("messages", [])

    # Extract user message
    from .utils import extract_user_message

    user_message = extract_user_message(messages) or "–ê–Ω–∞–ª—ñ–∑ —Ñ–æ—Ç–æ"

    # Build deps with image context
    deps = create_deps_from_state(state)
    deps.has_image = True
    deps.image_url = state.get("image_url") or state.get("metadata", {}).get("image_url")
    deps.current_state = State.STATE_2_VISION.value

    logger.info(
        "üñºÔ∏è [SESSION %s] Vision node started: image=%s",
        session_id,
        deps.image_url[:60] if deps.image_url else "None",
    )

    try:
        # Call vision agent
        response = await run_vision(message=user_message, deps=deps)

        # Enrich product from DB if Vision returned partial data (missing id/photo/price)
        if response.identified_product and (
            response.identified_product.price == 0
            or not response.identified_product.photo_url
            or not response.identified_product.id
        ):
            # –ü–µ—Ä–µ–¥–∞—î–º–æ –∫–æ–ª—ñ—Ä –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ match –≤ –ë–î!
            vision_color = response.identified_product.color
            enriched = await _enrich_product_from_db(
                response.identified_product.name, 
                color=vision_color
            )
            if enriched:
                # Update identified_product with DB data (DB = —î–¥–∏–Ω–µ –¥–∂–µ—Ä–µ–ª–æ –ø—Ä–∞–≤–¥–∏)
                response.identified_product.price = enriched.get("price", 0)
                response.identified_product.photo_url = enriched.get("photo_url", "")
                # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∫–æ–ª—ñ—Ä –≤—ñ–¥ vision —è–∫—â–æ –≤—ñ–Ω —î, —ñ–Ω–∞–∫—à–µ –±–µ—Ä–µ–º–æ –∑ –ë–î
                if not vision_color:
                    response.identified_product.color = enriched.get("color", "")
                response.identified_product.id = enriched.get("id", 0)

                # –ù–ï –≥–µ–Ω–µ—Ä—É—î–º–æ reply –∑ —Ü—ñ–Ω–æ—é —Ç—É—Ç!
                # –¶—ñ–Ω–∞ –∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ —Ä–æ–∑–º—ñ—Ä—É, —Ç–æ–º—É –ø–∏—Ç–∞—î–º–æ —Ä–æ–∑–º—ñ—Ä —Å–ø–æ—á–∞—Ç–∫—É.
                # _build_vision_messages() —Å—Ç–≤–æ—Ä—é—î –ø—Ä–∞–≤–∏–ª—å–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å.

        # Log response with clear visibility
        product_name = (
            response.identified_product.name if response.identified_product else "<not identified>"
        )
        product_price = response.identified_product.price if response.identified_product else 0
        logger.info(
            "üñºÔ∏è [SESSION %s] Vision RESULT: product='%s' price=%s confidence=%.0f%%",
            session_id,
            product_name,
            product_price,
            response.confidence * 100,
        )

        # Async trace logging (disabled by default via AsyncTracingService flag)
        try:
            await log_trace(
                session_id=session_id or "",
                trace_id=f"vision:{session_id}:{int(start_time * 1000)}",
                node_name="vision_node",
                state_name=State.STATE_2_VISION.value,
                prompt_key="vision_main",
                input_snapshot={
                    "message": user_message,
                    "image_url": deps.image_url,
                },
                output_snapshot={
                    "product_name": product_name,
                    "price": product_price,
                    "confidence": response.confidence,
                },
                latency_ms=(time.perf_counter() - start_time) * 1000,
                model_name=None,
            )
        except Exception as trace_error:  # Observability must not break main flow
            logger.debug("Vision trace logging skipped: %s", trace_error)

        # Extract products and build messages using helpers
        selected_products = _extract_products(response, state.get("selected_products", []))

        metadata = state.get("metadata", {})
        vision_greeted_before = bool(metadata.get("vision_greeted", False))
        assistant_messages = _build_vision_messages(
            response,
            messages,
            vision_greeted=vision_greeted_before,
            user_message=user_message,  # –ü–µ—Ä–µ–¥–∞—î–º–æ —Ç–µ–∫—Å—Ç –¥–ª—è –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –∑—Ä–æ—Å—Ç—É!
        )

        # Metrics
        latency_ms = (time.perf_counter() - start_time) * 1000
        log_agent_step(
            session_id=session_id,
            state=State.STATE_2_VISION.value,
            intent="PHOTO_IDENT",
            event="vision_complete",
            latency_ms=latency_ms,
            extra={
                "products_count": len(selected_products),
                "confidence": response.confidence,
            },
        )
        track_metric("vision_node_latency_ms", latency_ms)

        # =====================================================
        # DIALOG PHASE (Turn-Based State Machine)
        # =====================================================
        # –í–∏–∑–Ω–∞—á–∞—î–º–æ –Ω–∞—Å—Ç—É–ø–Ω—É —Ñ–∞–∑—É –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É Vision:
        #
        # 1. –¢–æ–≤–∞—Ä –≤–ø—ñ–∑–Ω–∞–Ω–æ ‚Üí WAITING_FOR_SIZE (STATE_3)
        #    - –í–∂–µ –ø–æ–∫–∞–∑–∞–ª–∏ —Ç–æ–≤–∞—Ä, –ø–∏—Ç–∞—î–º–æ –∑—Ä—ñ—Å—Ç
        #    - –ù–∞—Å—Ç—É–ø–Ω–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è —é–∑–µ—Ä–∞ –π–¥–µ –≤ agent
        #
        # 2. –¢–æ–≤–∞—Ä –ù–ï –≤–ø—ñ–∑–Ω–∞–Ω–æ ‚Üí VISION_DONE
        #    - –ü–æ—Ç—Ä—ñ–±–Ω–æ —É—Ç–æ—á–Ω–µ–Ω–Ω—è –≤—ñ–¥ —é–∑–µ—Ä–∞
        #
        # 3. needs_clarification ‚Üí VISION_DONE
        #    - Vision –Ω–µ –≤–ø–µ–≤–Ω–µ–Ω–∏–π, –ø–∏—Ç–∞—î —É—Ç–æ—á–Ω–µ–Ω–Ω—è
        # =====================================================
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –∑—Ä—ñ—Å—Ç –≤–∂–µ —î –≤ —Ç–µ–∫—Å—Ç—ñ
        height_in_text = extract_height_from_text(user_message)
        
        if selected_products:
            if height_in_text:
                # –ó—Ä—ñ—Å—Ç –≤–∂–µ —î - –≥–æ—Ç–æ–≤—ñ –¥–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–Ω—è!
                next_phase = "SIZE_COLOR_DONE"
                next_state = State.STATE_4_OFFER.value
            else:
                # –¢—ñ–ª—å–∫–∏ —Ñ–æ—Ç–æ - —á–µ–∫–∞—î–º–æ –∑—Ä—ñ—Å—Ç
                next_phase = "WAITING_FOR_SIZE"
                next_state = State.STATE_3_SIZE_COLOR.value
        elif response.needs_clarification:
            next_phase = "VISION_DONE"
            next_state = State.STATE_2_VISION.value
        else:
            next_phase = "INIT"
            next_state = State.STATE_0_INIT.value

        return {
            "current_state": next_state,
            "messages": assistant_messages,
            "selected_products": selected_products,
            "dialog_phase": next_phase,
            # –í–ê–ñ–õ–ò–í–û: –°–∫–∏–¥–∞—î–º–æ has_image –ø—ñ—Å–ª—è –æ–±—Ä–æ–±–∫–∏!
            # –¶–µ –∑–∞–ø–æ–±—ñ–≥–∞—î –ø–æ–≤—Ç–æ—Ä–Ω–æ–º—É –≤—Ö–æ–¥—É –≤ vision –ø—Ä–∏ –Ω–∞—Å—Ç—É–ø–Ω–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è—Ö
            "has_image": False,
            "metadata": {
                **state.get("metadata", {}),
                "vision_confidence": response.confidence,
                "needs_clarification": response.needs_clarification,
                "has_image": False,  # –¢–∞–∫–æ–∂ –≤ metadata
                "vision_greeted": True,  # greeting —É–∂–µ –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–æ
            },
            # Lightweight agent_response so renderers (Telegram/ManyChat) –º–æ–∂—É—Ç—å –ø–æ–∫–∞–∑–∞—Ç–∏ —Ñ–æ—Ç–æ/—Ç–µ–∫—Å—Ç
            "agent_response": {
                "event": "simple_answer",
                "messages": [
                    {"type": "text", "content": m.get("content", "")}
                    for m in assistant_messages
                    if m.get("type") == "text"
                ],
                "products": selected_products,
                "metadata": {
                    "session_id": session_id,
                    "current_state": next_state,
                    "intent": "PHOTO_IDENT",
                    "escalation_level": "NONE",
                },
            },
            "step_number": state.get("step_number", 0) + 1,
            "last_error": None,
        }

    except Exception as e:
        logger.exception("Vision node failed: %s", e)
        return {
            "last_error": str(e),
            "tool_errors": [*state.get("tool_errors", []), f"Vision error: {e}"],
            "retry_count": state.get("retry_count", 0) + 1,
            "step_number": state.get("step_number", 0) + 1,
        }
